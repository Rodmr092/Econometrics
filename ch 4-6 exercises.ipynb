{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4, inference / hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Cargar datos\n",
    "data = wooldridge.data('vote1')\n",
    "\n",
    "vote = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo \n",
    "model = ols('voteA ~ lexpendA + lexpendB + prtystrA', data=vote).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  voteA   R-squared:                       0.793\n",
      "Model:                            OLS   Adj. R-squared:                  0.789\n",
      "Method:                 Least Squares   F-statistic:                     215.2\n",
      "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           1.76e-57\n",
      "Time:                        17:27:40   Log-Likelihood:                -596.86\n",
      "No. Observations:                 173   AIC:                             1202.\n",
      "Df Residuals:                     169   BIC:                             1214.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     45.0789      3.926     11.481      0.000      37.328      52.830\n",
      "lexpendA       6.0833      0.382     15.919      0.000       5.329       6.838\n",
      "lexpendB      -6.6154      0.379    -17.463      0.000      -7.363      -5.868\n",
      "prtystrA       0.1520      0.062      2.450      0.015       0.030       0.274\n",
      "==============================================================================\n",
      "Omnibus:                        8.900   Durbin-Watson:                   1.604\n",
      "Prob(Omnibus):                  0.012   Jarque-Bera (JB):                8.832\n",
      "Skew:                           0.493   Prob(JB):                       0.0121\n",
      "Kurtosis:                       3.505   Cond. No.                         344.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) **interpretation of b1**\n",
    "b1 models a level-log relationship, but vote is a percentage, a change of 1% in expendA changes the predicted percentage of vote by .06% in a similar direction of the change.\n",
    "\n",
    "(ii)**In terms of the parameters, state the null hypothesis that a 1% increase in A’s expenditures is offset by a 1% increase in B’s expenditures.** H0 : B1 = -B2\n",
    "\n",
    "(iii) **Estimate the given model using the data in VOTE1.RAW and report the results \n",
    "in usual form. Do A’s expenditures affect the outcome? What about B’s expenditures? Can you use these results to test the hypothesis in part (ii)?** lexpendA has a coef of 6.08 and a std error of .382, which gives us a t statistic of 15.9 which means it is very significant both practically as statistically. Similarly, lexpendB has a coef of -6.61, a SD of .379 and a t of -17.463. It is also both practically and statistically significant and important. Both have similar results in the opposite direction, which is expected due to the non-zero sum aspect of an election. Further analysis is required to quantify and reject the hypothesis that a 1% increase in A is offset by 1% increase in B, such as applying a t test between the two parameters, which would require us to estimate a model that gives the t statistic for testing the hypothesis by reparametrization or to compute the standard error of B1-B2\n",
    "\n",
    "(iv) Estimate a model that directly gives the t statistic for testing the hypothesis in part \n",
    "(ii). What do you conclude? (Use a two-sided alternative.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voteA = β₀ + β₁lexpendA + β₂lexpendB + β₃prtystrA + u\n",
    "\n",
    "Hypothesis: H0:B1=-B2\n",
    "\n",
    "we sum and substract B2expend, to obtain the coefficient B1+B2 and prove if it is 0\n",
    "\n",
    "voteA = β₀ + β₁lexpendA + β₂lexpendB + β₂lexpendA - β₂lexpendA + β₃prtystrA + u\n",
    "\n",
    "voteA = β₀ + β₂(lexpendA + lexpendB) + (β₁ + β₂)lexpendA + β₃prtystrA + u\n",
    "\n",
    "θ = β₂ (coeficiente de sum_expend)\n",
    "γ = β₁ + β₂ (coeficiente de lexpendA)\n",
    "\n",
    "voteA = β₀ + θ(lexpendA + lexpendB) + γ(lexpendA) + β₃prtystrA + u\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo reparametrizado:\n",
      "=====================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  voteA   R-squared:                       0.793\n",
      "Model:                            OLS   Adj. R-squared:                  0.789\n",
      "Method:                 Least Squares   F-statistic:                     215.2\n",
      "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           1.76e-57\n",
      "Time:                        17:58:27   Log-Likelihood:                -596.86\n",
      "No. Observations:                 173   AIC:                             1202.\n",
      "Df Residuals:                     169   BIC:                             1214.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     45.0789      3.926     11.481      0.000      37.328      52.830\n",
      "sum_expend    -6.6154      0.379    -17.463      0.000      -7.363      -5.868\n",
      "lexpendA      12.6987      0.543     23.384      0.000      11.627      13.771\n",
      "prtystrA       0.1520      0.062      2.450      0.015       0.030       0.274\n",
      "==============================================================================\n",
      "Omnibus:                        8.900   Durbin-Watson:                   1.604\n",
      "Prob(Omnibus):                  0.012   Jarque-Bera (JB):                8.832\n",
      "Skew:                           0.493   Prob(JB):                       0.0121\n",
      "Kurtosis:                       3.505   Cond. No.                         349.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Prueba de hipótesis H₀: β₁ = -β₂\n",
      "===================================\n",
      "t-estadístico: 23.3840\n",
      "p-valor: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Answer to 4:\n",
    "from scipy import stats  \n",
    "\n",
    "# Crear nueva variable que representa la suma de los coeficientes\n",
    "vote['sum_expend'] = vote['lexpendA'] + vote['lexpendB']\n",
    "\n",
    "# Modelo reparametrizado\n",
    "# voteA = β₀ + θ(lexpendA + lexpendB) + γ(lexpendA) + β₃prtystrA + u\n",
    "# donde γ = (β₁ + β₂)/2 es el coeficiente que queremos probar si es 0\n",
    "modelo_rep = ols('voteA ~ sum_expend + lexpendA + prtystrA', data=vote).fit()\n",
    "\n",
    "print(\"Resultados del modelo reparametrizado:\")\n",
    "print(\"=====================================\")\n",
    "print(modelo_rep.summary())\n",
    "\n",
    "# Calcular el p-valor para la prueba de dos colas\n",
    "t_stat = modelo_rep.tvalues['lexpendA']\n",
    "p_valor = 2 * (1 - stats.t.cdf(abs(t_stat), df=modelo_rep.df_resid))\n",
    "\n",
    "print(\"\\nPrueba de hipótesis H₀: β₁ = -β₂\")\n",
    "print(\"===================================\")\n",
    "print(f\"t-estadístico: {t_stat:.4f}\")\n",
    "print(f\"p-valor: {p_valor:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iv) with a t statistic of 23.38 and a p value of almost 0, we can reject the null hipothesis that B1 = -B2. This means that the effects in expenditure aren't symmetric, where the expenditures by candidate B have a marginally bigger effect in voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C2 \n",
    "LSAT is the median LSAT score for the graduating class, GPA is the median college \n",
    "GPA for the class, libvol is the number of volumes in the law school library, cost is the an\u0002nual cost of attending law school, and rank is a law school ranking (with rank 5 1 being \n",
    "the best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "\n",
    "data = woo.data('lawsch85')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de la Regresión:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                lsalary   R-squared:                       0.842\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     138.2\n",
      "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           2.93e-50\n",
      "Time:                        18:28:35   Log-Likelihood:                 107.33\n",
      "No. Observations:                 136   AIC:                            -202.7\n",
      "Df Residuals:                     130   BIC:                            -185.2\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      8.3432      0.533     15.667      0.000       7.290       9.397\n",
      "LSAT           0.0047      0.004      1.171      0.244      -0.003       0.013\n",
      "GPA            0.2475      0.090      2.749      0.007       0.069       0.426\n",
      "llibvol        0.0950      0.033      2.857      0.005       0.029       0.161\n",
      "lcost          0.0376      0.032      1.170      0.244      -0.026       0.101\n",
      "rank          -0.0033      0.000     -9.541      0.000      -0.004      -0.003\n",
      "==============================================================================\n",
      "Omnibus:                        0.198   Durbin-Watson:                   1.706\n",
      "Prob(Omnibus):                  0.906   Jarque-Bera (JB):                0.365\n",
      "Skew:                           0.037   Prob(JB):                        0.833\n",
      "Kurtosis:                       2.757   Cond. No.                     9.89e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.89e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "modelo = ols('lsalary ~ LSAT + GPA + llibvol + lcost + rank', data=data)\n",
    "\n",
    "resultados = modelo.fit()\n",
    "\n",
    "\n",
    "print(\"\\nResultados de la Regresión:\")\n",
    "print(resultados.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i)state and test the null hypothesis \n",
    "that the rank of law schools has no ceteris paribus effect on median starting salary.\n",
    "\n",
    "H0: Brank = 0\n",
    "\n",
    "the t statistic of rank is -9.541, which indicates that the rank of the school has a statistically significant effect on salary.The effect is low when compared to other variables. As it is a log-level relationship, each ranking point is equal to .33% in a change in the salary.\n",
    "\n",
    "(ii) Are features of the incoming class of students—namely, LSAT and GPA—\n",
    "individually or jointly significant for explaining salary? (Be sure to account for \n",
    "missing data on LSAT and GPA.)\n",
    "\n",
    "Lsat doesn't seem to have individual significancy. To evaluate joint significance, one may use the F test to evaluate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 136.0\n",
      "\n",
      "F-statistic: 9.9518\n",
      "p-value: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load and clean data\n",
    "data = woo.data('lawsch85')\n",
    "data_clean = data.dropna(subset=['LSAT', 'GPA', 'lsalary', 'llibvol', 'lcost', 'rank'])\n",
    "\n",
    "# Estimate models\n",
    "full_model = ols('lsalary ~ LSAT + GPA + llibvol + lcost + rank', data=data_clean).fit()\n",
    "restricted_model = ols('lsalary ~ llibvol + lcost + rank', data=data_clean).fit()\n",
    "\n",
    "# F-test for joint significance\n",
    "n = full_model.nobs\n",
    "k_full = full_model.df_model\n",
    "k_restricted = restricted_model.df_model\n",
    "q = k_full - k_restricted  # number of restrictions\n",
    "\n",
    "F = ((full_model.rsquared - restricted_model.rsquared) / q) / \\\n",
    "    ((1 - full_model.rsquared) / (n - k_full - 1))\n",
    "p_value = 1 - stats.f.cdf(F, q, n - k_full - 1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"\\nF-statistic: {F:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are jointly significant.\n",
    "\n",
    "(iii) Test whether the size of the entering class (clsize) or the size of the faculty \n",
    "( faculty) needs to be added to this equation; carry out a single test. (Be careful to \n",
    "account for missing data on clsize and faculty.)\n",
    "\n",
    "H0 : Bclsize, Bfaculty = 0\n",
    "H1 : Bclsize, Bfaculty =/ 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 131.0\n",
      "\n",
      "F-test for joint significance of class size and faculty:\n",
      "F-statistic: 0.9484\n",
      "p-value: 0.3902\n",
      "\n",
      "Coefficients for added variables:\n",
      "Variable    Coefficient    Std Error     t-stat    p-value\n",
      "-------------------------------------------------------\n",
      "clsize           0.0001       0.0002     0.8741     0.3838\n",
      "faculty          0.0001       0.0004     0.1687     0.8663\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "from statsmodels.formula.api import ols\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load and clean data\n",
    "data = woo.data('lawsch85')\n",
    "data_clean = data.dropna(subset=['LSAT', 'GPA', 'lsalary', 'llibvol', 'lcost', 'rank', 'clsize', 'faculty'])\n",
    "\n",
    "# Extended model\n",
    "extended_model = ols('lsalary ~ LSAT + GPA + llibvol + lcost + rank + clsize + faculty', \n",
    "                    data=data_clean).fit()\n",
    "\n",
    "# Base model\n",
    "base_model = ols('lsalary ~ LSAT + GPA + llibvol + lcost + rank', \n",
    "                data=data_clean).fit()\n",
    "\n",
    "# F-test\n",
    "n = base_model.nobs\n",
    "k_extended = extended_model.df_model\n",
    "k_base = base_model.df_model\n",
    "q = k_extended - k_base\n",
    "\n",
    "F = ((extended_model.rsquared - base_model.rsquared) / q) / \\\n",
    "    ((1 - extended_model.rsquared) / (n - k_extended - 1))\n",
    "p_value = 1 - stats.f.cdf(F, q, n - k_extended - 1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"\\nF-test for joint significance of class size and faculty:\")\n",
    "print(f\"F-statistic: {F:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "print(\"\\nCoefficients for added variables:\")\n",
    "print(f\"{'Variable':<10} {'Coefficient':>12} {'Std Error':>12} {'t-stat':>10} {'p-value':>10}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'clsize':<10} {extended_model.params['clsize']:12.4f} \"\n",
    "      f\"{extended_model.bse['clsize']:12.4f} \"\n",
    "      f\"{(extended_model.params['clsize']/extended_model.bse['clsize']):10.4f} \"\n",
    "      f\"{extended_model.pvalues['clsize']:10.4f}\")\n",
    "print(f\"{'faculty':<10} {extended_model.params['faculty']:12.4f} \"\n",
    "      f\"{extended_model.bse['faculty']:12.4f} \"\n",
    "      f\"{(extended_model.params['faculty']/extended_model.bse['faculty']):10.4f} \"\n",
    "      f\"{extended_model.pvalues['faculty']:10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F statistic is .9484 and the p-value is .3902\n",
    "There is very little evidence that adding clsize and faculty will improve the model, so we fail to reject H0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iv) What factors might influence the rank of the law school that are not included in the model?\n",
    "\n",
    "- Bar passage rate\n",
    "- Student acceptance ratio\n",
    "- Number and quality of academic papers\n",
    "- Ratio of employment after graduation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the log of the housing price as the \n",
    "dependent variable:\n",
    "log(price) = b0 + b1sqrft + b2bdrms + u.\n",
    "(i) You are interested in estimating and obtaining a confidence interval for the percent\u0002age change in price when a 150-square-foot bedroom is added to a house. In decimal \n",
    "form, this is θ = 150b1 + b2. Use the data in HPRICE1.RAW to estimate θ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['price', 'assess', 'bdrms', 'lotsize', 'sqrft', 'colonial', 'lprice',\n",
      "       'lassess', 'llotsize', 'lsqrft'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import wooldridge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = wooldridge.data('hprice1')\n",
    "\n",
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ols('lprice ~ sqrft + bdrms', data=data).fit()\n",
    "\n",
    "beta1 = model.params['sqrft']\n",
    "beta2 = model.params['bdrms']\n",
    "\n",
    "# Theta 1 which represents a new bedroom of 150 sqrft\n",
    "theta1 = 150 * beta1 + beta2\n",
    "\n",
    "# Covariance matrix\n",
    "vcov = model.cov_params()\n",
    "\n",
    "# Standard error of theta1\n",
    "var_theta1 = (150**2 * vcov.loc['sqrft', 'sqrft'] +\n",
    "              vcov.loc['bdrms', 'bdrms'] +\n",
    "              2 * 150 * vcov.loc['sqrft', 'bdrms'])\n",
    "se_theta1 = np.sqrt(var_theta1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados del Análisis:\n",
      "========================\n",
      "                 Métrica    Valor\n",
      "   θ₁ (efecto combinado) 0.085801\n",
      "          Error Estándar 0.026768\n",
      "IC 95% - Límite Inferior 0.032580\n",
      "IC 95% - Límite Superior 0.139022\n",
      "       Efecto Porcentual 8.958985\n"
     ]
    }
   ],
   "source": [
    "# Confidence interval of price when theta1 (a 150 ft room) is added \n",
    "degrees_of_freedom = model.df_resid\n",
    "t_critical = stats.t.ppf(0.975, degrees_of_freedom)\n",
    "ci_lower = theta1 - t_critical * se_theta1\n",
    "ci_upper = theta1 + t_critical * se_theta1\n",
    "\n",
    "# Dataframe with the results\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Métrica': ['θ₁ (efecto combinado)', \n",
    "                'Error Estándar', \n",
    "                'IC 95% - Límite Inferior',\n",
    "                'IC 95% - Límite Superior',\n",
    "                'Efecto Porcentual'],\n",
    "    'Valor': [theta1, \n",
    "              se_theta1, \n",
    "              ci_lower, \n",
    "              ci_upper,\n",
    "              (np.exp(theta1) - 1) * 100]  # Conversión a cambio porcentual exacto\n",
    "})\n",
    "\n",
    "print(\"\\nResultados del Análisis:\")\n",
    "print(\"========================\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas del Modelo:\n",
      "=======================\n",
      "R² ajustado: 0.5786\n",
      "Estadístico F: 60.73\n",
      "Valor p (F): 4.1679e-17\n"
     ]
    }
   ],
   "source": [
    "# Imprimir estadísticas adicionales del modelo\n",
    "print(\"\\nEstadísticas del Modelo:\")\n",
    "print(\"=======================\")\n",
    "print(f\"R² ajustado: {model.rsquared_adj:.4f}\")\n",
    "print(f\"Estadístico F: {model.fvalue:.2f}\")\n",
    "print(f\"Valor p (F): {model.f_pvalue:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coeficientes Individuales:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.7660      0.097     49.112      0.000       4.573       4.959\n",
      "sqrft          0.0004   4.32e-05      8.781      0.000       0.000       0.000\n",
      "bdrms          0.0289      0.030      0.974      0.333      -0.030       0.088\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imprimir los coeficientes individuales y sus estadísticas\n",
    "print(\"\\nCoeficientes Individuales:\")\n",
    "print(model.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4\n",
    "\n",
    "This exercise asks to compute an F statistic to determine if parents' education are statistically significant on an incomplete dataset, so that we can compare the results of when it is computed on the data that is complete.\n",
    "\n",
    "The unrestricted model is bwght = β₀ + β₁cigs + β₂parity + β₃faminc + β₄motheduc + β₅fatheduc + u\n",
    "\n",
    "The sample size is 1388, of which only 1191 where used.  R² unrestricted: 0.0387. R² restricted: 0.0364. F: 1.42, mother and father education are statistically insignificant.\n",
    "\n",
    "Next, we compute the same on the whole dataset, ignoring that there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de observaciones en el dataset: 1388\n",
      "\n",
      "Observaciones disponibles por variable:\n",
      "bwght: 1388 observaciones válidas\n",
      "cigs: 1388 observaciones válidas\n",
      "parity: 1388 observaciones válidas\n",
      "faminc: 1388 observaciones válidas\n",
      "\n",
      "Resultados:\n",
      "Observaciones usadas en Example 4.9 (con datos completos): 1191\n",
      "R² reportado en Example 4.9 (1,191 obs): 0.0364\n",
      "R² calculado con las mismas 1,191 obs: 0.0364\n",
      "\n",
      "Observaciones usadas en modelo restringido (ejercicio C4): 1388\n",
      "R² del modelo restringido (usando todas las obs válidas): 0.0348\n"
     ]
    }
   ],
   "source": [
    "import wooldridge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar los datos\n",
    "data = wooldridge.data('bwght')\n",
    "\n",
    "# Verificar el número total de observaciones\n",
    "print(f\"Número total de observaciones en el dataset: {len(data)}\")\n",
    "\n",
    "# 1. Modelo restringido usando todas las observaciones válidas para bwght, cigs, parity, faminc\n",
    "# Primero veamos cuántas observaciones tenemos para cada variable\n",
    "print(\"\\nObservaciones disponibles por variable:\")\n",
    "for col in ['bwght', 'cigs', 'parity', 'faminc']:\n",
    "    print(f\"{col}: {data[col].count()} observaciones válidas\")\n",
    "\n",
    "# Ahora seleccionamos solo las variables necesarias para el modelo restringido\n",
    "X_vars = ['cigs', 'parity', 'faminc']\n",
    "mask = data[['bwght'] + X_vars].notna().all(axis=1)\n",
    "model_restricted_full = data[mask]\n",
    "\n",
    "X_restricted_full = model_restricted_full[X_vars]\n",
    "y_full = model_restricted_full['bwght']\n",
    "\n",
    "# Añadir constante\n",
    "X_restricted_full = pd.concat([pd.Series(1, index=X_restricted_full.index, name='const'), \n",
    "                             X_restricted_full], axis=1)\n",
    "\n",
    "# Calcular beta usando OLS\n",
    "beta_restricted_full = np.linalg.inv(X_restricted_full.T @ X_restricted_full) @ (X_restricted_full.T @ y_full)\n",
    "\n",
    "# Calcular valores ajustados y R² para modelo restringido con todas las observaciones válidas\n",
    "y_hat_restricted_full = X_restricted_full @ beta_restricted_full\n",
    "mean_y_full = np.mean(y_full)\n",
    "r2_restricted_full = 1 - (np.sum((y_full - y_hat_restricted_full)**2) / \n",
    "                         np.sum((y_full - mean_y_full)**2))\n",
    "\n",
    "# 2. Modelo restringido usando solo las 1,191 observaciones (del Example 4.9)\n",
    "mask_complete = data[['bwght', 'cigs', 'parity', 'faminc', 'motheduc', 'fatheduc']].notna().all(axis=1)\n",
    "model_complete = data[mask_complete]\n",
    "X_restricted = model_complete[X_vars]\n",
    "y = model_complete['bwght']\n",
    "\n",
    "# Añadir constante\n",
    "X_restricted = pd.concat([pd.Series(1, index=X_restricted.index, name='const'), \n",
    "                         X_restricted], axis=1)\n",
    "\n",
    "# Calcular beta usando OLS\n",
    "beta_restricted = np.linalg.inv(X_restricted.T @ X_restricted) @ (X_restricted.T @ y)\n",
    "\n",
    "# Calcular valores ajustados y R² para modelo restringido\n",
    "y_hat_restricted = X_restricted @ beta_restricted\n",
    "mean_y = np.mean(y)\n",
    "r2_restricted = 1 - (np.sum((y - y_hat_restricted)**2) / \n",
    "                     np.sum((y - mean_y)**2))\n",
    "\n",
    "print(\"\\nResultados:\")\n",
    "print(f\"Observaciones usadas en Example 4.9 (con datos completos): {len(model_complete)}\")\n",
    "print(f\"R² reportado en Example 4.9 (1,191 obs): 0.0364\")\n",
    "print(f\"R² calculado con las mismas 1,191 obs: {r2_restricted:.4f}\")\n",
    "print(f\"\\nObservaciones usadas en modelo restringido (ejercicio C4): {len(model_restricted_full)}\")\n",
    "print(f\"R² del modelo restringido (usando todas las obs válidas): {r2_restricted_full:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R² is slightly lower when we use all the available samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C5\n",
    "\n",
    "\n",
    "Starting from the following equation:\n",
    "```log(salary) = 11.19 + 0.0689 years + 0.0126 gamesyr + 0.00098 bavg + 0.0144 hrunsyr + 0.0108 rbisyr```\n",
    "\n",
    "We will analyze:\n",
    "1. The effect of omitting rbisyr over the coefficient of hrunsyr\n",
    "2. The impact of including runsyr, fldperc y sbasesyr to the model\n",
    "3. The joint significance of bavg, fldperc y sbasesyr.\n",
    "\n",
    "Dataset: MLB1.RAW, Wooldridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['salary', 'teamsal', 'nl', 'years', 'games', 'atbats', 'runs', 'hits',\n",
      "       'doubles', 'triples', 'hruns', 'rbis', 'bavg', 'bb', 'so', 'sbases',\n",
      "       'fldperc', 'frstbase', 'scndbase', 'shrtstop', 'thrdbase', 'outfield',\n",
      "       'catcher', 'yrsallst', 'hispan', 'black', 'whitepop', 'blackpop',\n",
      "       'hisppop', 'pcinc', 'gamesyr', 'hrunsyr', 'atbatsyr', 'allstar',\n",
      "       'slugavg', 'rbisyr', 'sbasesyr', 'runsyr', 'percwhte', 'percblck',\n",
      "       'perchisp', 'blckpb', 'hispph', 'whtepw', 'blckph', 'hisppb',\n",
      "       'lsalary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar los datos\n",
    "mlb = woo.data('mlb1')\n",
    "\n",
    "print(mlb.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model\n",
    "X_orig = sm.add_constant(mlb[['years', 'gamesyr', 'bavg', 'hrunsyr', 'rbisyr']])\n",
    "y = mlb['lsalary']\n",
    "\n",
    "modelo_original = sm.OLS(y, X_orig).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) model without rbisyr\n",
    "X_sin_rbi = sm.add_constant(mlb[['years', 'gamesyr', 'bavg', 'hrunsyr']])\n",
    "modelo_sin_rbi = sm.OLS(y, X_sin_rbi).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with additional vars\n",
    "X_completo = sm.add_constant(mlb[['years', 'gamesyr', 'bavg', 'hrunsyr', 'runsyr', 'fldperc', 'sbasesyr']])\n",
    "\n",
    "modelo_completo = sm.OLS(y, X_completo).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_comparison():\n",
    "    print(\"=== Comparación de Modelos ===\\n\")\n",
    "    \n",
    "    # Resultados del modelo original\n",
    "    print(\"Modelo Original (ecuación 4.31):\")\n",
    "    print(modelo_original.summary().tables[1])\n",
    "    print(\"\\nR-cuadrado:\", round(modelo_original.rsquared, 4))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Resultados del modelo sin rbisyr\n",
    "    print(\"Modelo sin rbisyr:\")\n",
    "    print(modelo_sin_rbi.summary().tables[1])\n",
    "    print(\"\\nR-cuadrado:\", round(modelo_sin_rbi.rsquared, 4))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Resultados del modelo completo\n",
    "    print(\"Modelo Completo (con variables adicionales):\")\n",
    "    print(modelo_completo.summary().tables[1])\n",
    "    print(\"\\nR-cuadrado:\", round(modelo_completo.rsquared, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_joint_significance():\n",
    "    # Prueba F para la significancia conjunta de bavg, fldperc y sbasesyr\n",
    "    # Crear modelos restringido y no restringido\n",
    "    variables_restriccion = ['bavg', 'fldperc', 'sbasesyr']\n",
    "    variables_base = ['years', 'gamesyr', 'hrunsyr', 'runsyr']\n",
    "    \n",
    "    # Modelo no restringido (completo)\n",
    "    X_no_restringido = sm.add_constant(mlb[variables_base + variables_restriccion])\n",
    "    modelo_no_restringido = sm.OLS(y, X_no_restringido).fit()\n",
    "    \n",
    "    # Modelo restringido (sin las variables a probar)\n",
    "    X_restringido = sm.add_constant(mlb[variables_base])\n",
    "    modelo_restringido = sm.OLS(y, X_restringido).fit()\n",
    "    \n",
    "    # Calcular estadístico F\n",
    "    n = len(y)\n",
    "    k_no_restringido = len(X_no_restringido.columns)\n",
    "    k_restringido = len(X_restringido.columns)\n",
    "    q = k_no_restringido - k_restringido\n",
    "    \n",
    "    F_stat = ((modelo_restringido.ssr - modelo_no_restringido.ssr) / q) / \\\n",
    "             (modelo_no_restringido.ssr / (n - k_no_restringido))\n",
    "    \n",
    "    p_value = 1 - stats.f.cdf(F_stat, q, n - k_no_restringido)\n",
    "    \n",
    "    print(\"\\n=== Prueba F de Significancia Conjunta ===\")\n",
    "    print(f\"Variables probadas: {', '.join(variables_restriccion)}\")\n",
    "    print(f\"Estadístico F: {F_stat:.4f}\")\n",
    "    print(f\"Valor p: {p_value:.4f}\")\n",
    "    print(f\"Grados de libertad: ({q}, {n - k_no_restringido})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comparación de Modelos ===\n",
      "\n",
      "Modelo Original (ecuación 4.31):\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         11.1924      0.289     38.752      0.000      10.624      11.760\n",
      "years          0.0689      0.012      5.684      0.000       0.045       0.093\n",
      "gamesyr        0.0126      0.003      4.742      0.000       0.007       0.018\n",
      "bavg           0.0010      0.001      0.887      0.376      -0.001       0.003\n",
      "hrunsyr        0.0144      0.016      0.899      0.369      -0.017       0.046\n",
      "rbisyr         0.0108      0.007      1.500      0.134      -0.003       0.025\n",
      "==============================================================================\n",
      "\n",
      "R-cuadrado: 0.6278\n",
      "\n",
      "==================================================\n",
      "\n",
      "Modelo sin rbisyr:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         11.0209      0.266     41.476      0.000      10.498      11.544\n",
      "years          0.0677      0.012      5.592      0.000       0.044       0.092\n",
      "gamesyr        0.0158      0.002     10.079      0.000       0.013       0.019\n",
      "bavg           0.0014      0.001      1.331      0.184      -0.001       0.004\n",
      "hrunsyr        0.0359      0.007      4.964      0.000       0.022       0.050\n",
      "==============================================================================\n",
      "\n",
      "R-cuadrado: 0.6254\n",
      "\n",
      "==================================================\n",
      "\n",
      "Modelo Completo (con variables adicionales):\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.4083      2.003      5.196      0.000       6.468      14.348\n",
      "years          0.0700      0.012      5.844      0.000       0.046       0.094\n",
      "gamesyr        0.0079      0.003      2.950      0.003       0.003       0.013\n",
      "bavg           0.0005      0.001      0.480      0.632      -0.002       0.003\n",
      "hrunsyr        0.0232      0.009      2.687      0.008       0.006       0.040\n",
      "runsyr         0.0174      0.005      3.434      0.001       0.007       0.027\n",
      "fldperc        0.0010      0.002      0.516      0.606      -0.003       0.005\n",
      "sbasesyr      -0.0064      0.005     -1.238      0.216      -0.017       0.004\n",
      "==============================================================================\n",
      "\n",
      "R-cuadrado: 0.639\n",
      "\n",
      "=== Prueba F de Significancia Conjunta ===\n",
      "Variables probadas: bavg, fldperc, sbasesyr\n",
      "Estadístico F: 0.6850\n",
      "Valor p: 0.5617\n",
      "Grados de libertad: (3, 345)\n"
     ]
    }
   ],
   "source": [
    "print_results_comparison()\n",
    "test_joint_significance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hrunsyr increased its t value from 0.899 to 4.964, becoming highly significant. This is likely due to a multicolineality problem, which is logic as home runs will always result in at least 1 Run Batted in.\n",
    "\n",
    "Since Runs batted in depend so much on other variables, and R² barely changed, one can conclude that rbisyr and hrunsyr capture similar information. \n",
    "\n",
    "runsyr, fldperc and sbasesyr have the following coefficients:0.0174, 0.0010 and -0.0064, with respective t statistics of 3.43, 0.516 and -1.238. Runsyr seems to be significant, but one might have doubts about bavg, fldperc and sbasesyr. The joint significance of  bavg, fldperc and sbasesyr variables are very low, with an f statistic of 0.685 and a p value of .5617, which means that there is not enough evidence that they are providing jointly any information to the model, and should be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C6\n",
    "\n",
    "Using the data from WAGE2, estimate a log-level equation of salaries. Prove if general experience has the same effect as an extra year of remaining with the present employer. \n",
    "\n",
    "h0: β₂ = β₃\n",
    "H₁: β₂ ≠ β₃\n",
    "\n",
    "Significance: 5%\n",
    "Confidence interval: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from wooldridge import data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Cargar los datos\n",
    "df = data('wage2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['educ', 'exper', 'tenure']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['lwage']\n",
    "\n",
    "modelo = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados del Modelo de Regresión:\n",
      "===================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.155\n",
      "Model:                            OLS   Adj. R-squared:                  0.152\n",
      "Method:                 Least Squares   F-statistic:                     56.97\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           8.12e-34\n",
      "Time:                        17:48:47   Log-Likelihood:                -438.84\n",
      "No. Observations:                 935   AIC:                             885.7\n",
      "Df Residuals:                     931   BIC:                             905.0\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.4967      0.111     49.731      0.000       5.280       5.714\n",
      "educ           0.0749      0.007     11.495      0.000       0.062       0.088\n",
      "exper          0.0153      0.003      4.549      0.000       0.009       0.022\n",
      "tenure         0.0134      0.003      5.170      0.000       0.008       0.018\n",
      "==============================================================================\n",
      "Omnibus:                       20.917   Durbin-Watson:                   1.769\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.558\n",
      "Skew:                          -0.214   Prob(JB):                     2.31e-07\n",
      "Kurtosis:                       3.775   Cond. No.                         170.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Factores de Inflación de Varianza (VIF):\n",
      "=========================================\n",
      "\n",
      "Pruebas de Diagnóstico:\n",
      "======================\n",
      "R-cuadrado: 0.1551\n",
      "R-cuadrado ajustado: 0.1524\n",
      "Estadístico F: 56.9739\n",
      "Prob (F-statistic): 0.0000\n",
      "\n",
      "Interpretación de los Coeficientes:\n",
      "==================================\n",
      "\n",
      "educ: Un aumento de 1 año en educ está asociado con un cambio de 7.77% en el salario, manteniendo las otras variables constantes\n",
      "\n",
      "exper: Un aumento de 1 año en exper está asociado con un cambio de 1.54% en el salario, manteniendo las otras variables constantes\n",
      "\n",
      "tenure: Un aumento de 1 año en tenure está asociado con un cambio de 1.35% en el salario, manteniendo las otras variables constantes\n"
     ]
    }
   ],
   "source": [
    "# Imprimir resultados\n",
    "print(\"\\nResultados del Modelo de Regresión:\")\n",
    "print(\"===================================\")\n",
    "print(modelo.summary())\n",
    "print(\"\\nFactores de Inflación de Varianza (VIF):\")\n",
    "print(\"=========================================\")\n",
    "\n",
    "# Pruebas adicionales de diagnóstico\n",
    "print(\"\\nPruebas de Diagnóstico:\")\n",
    "print(\"======================\")\n",
    "print(f\"R-cuadrado: {modelo.rsquared:.4f}\")\n",
    "print(f\"R-cuadrado ajustado: {modelo.rsquared_adj:.4f}\")\n",
    "print(f\"Estadístico F: {modelo.fvalue:.4f}\")\n",
    "print(f\"Prob (F-statistic): {modelo.f_pvalue:.4f}\")\n",
    "\n",
    "# Interpretación de los coeficientes en términos porcentuales\n",
    "print(\"\\nInterpretación de los Coeficientes:\")\n",
    "print(\"==================================\")\n",
    "for var, coef in zip(X.columns, modelo.params):\n",
    "    if var != 'const':\n",
    "        print(f\"\\n{var}: Un aumento de 1 año en {var} está asociado con un cambio de {(np.exp(coef)-1)*100:.2f}% en el salario, manteniendo las otras variables constantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_exper = modelo.params['exper']\n",
    "beta_tenure = modelo.params['tenure']\n",
    "cov_matrix = modelo.cov_params()\n",
    "\n",
    "# Calcular la varianza de la diferencia\n",
    "# Var(β₂ - β₃) = Var(β₂) + Var(β₃) - 2Cov(β₂,β₃)\n",
    "\n",
    "var_diff = (cov_matrix.loc['exper', 'exper'] +\n",
    "            cov_matrix.loc['tenure', 'tenure'] -\n",
    "            2 * cov_matrix.loc['exper', 'tenure'])\n",
    "\n",
    "# Calcular estadístico t\n",
    "diff = beta_exper - beta_tenure\n",
    "se_diff = np.sqrt(var_diff)\n",
    "t_stat = diff / se_diff\n",
    "\n",
    "# Grados de libertad\n",
    "df_reg = modelo.df_resid\n",
    "\n",
    "# Valor crítico\n",
    "t_crit = stats.t.ppf(0.975, df_reg)\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df_reg))\n",
    "\n",
    "# Intervalo de confianza\n",
    "ic_lower = diff - t_crit * se_diff\n",
    "ic_upper = diff + t_crit * se_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba de Hipótesis: β_exper = β_tenure\n",
      "=======================================\n",
      "\n",
      "Coeficiente de experiencia (β_exper): 0.0153\n",
      "Coeficiente de tenure (β_tenure): 0.0134\n",
      "Diferencia (β_exper - β_tenure): 0.0020\n",
      "\n",
      "Error estándar de la diferencia: 0.0047\n",
      "Estadístico t: 0.4119\n",
      "Grados de libertad: 931.0\n",
      "Valor crítico (t_931.0,0.025): ±1.9625\n",
      "P-valor: 0.6805\n",
      "\n",
      "Intervalo de Confianza 95%\n",
      "==========================\n",
      "Límite inferior: -0.0074\n",
      "Límite superior: 0.0113\n"
     ]
    }
   ],
   "source": [
    "# Imprimir resultados\n",
    "print(\"Prueba de Hipótesis: β_exper = β_tenure\")\n",
    "print(\"=======================================\")\n",
    "print(f\"\\nCoeficiente de experiencia (β_exper): {beta_exper:.4f}\")\n",
    "print(f\"Coeficiente de tenure (β_tenure): {beta_tenure:.4f}\")\n",
    "print(f\"Diferencia (β_exper - β_tenure): {diff:.4f}\")\n",
    "print(f\"\\nError estándar de la diferencia: {se_diff:.4f}\")\n",
    "print(f\"Estadístico t: {t_stat:.4f}\")\n",
    "print(f\"Grados de libertad: {df_reg}\")\n",
    "print(f\"Valor crítico (t_{df_reg},0.025): ±{t_crit:.4f}\")\n",
    "print(f\"P-valor: {p_value:.4f}\")\n",
    "print(\"\\nIntervalo de Confianza 95%\")\n",
    "print(\"==========================\")\n",
    "print(f\"Límite inferior: {ic_lower:.4f}\")\n",
    "print(f\"Límite superior: {ic_upper:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a t value of .4119 there is not enough evidence that experience is different than tenure, so we can conclude that Bexper = Btenure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['female', 'phsrank', 'BA', 'AA', 'black', 'hispanic', 'id', 'exper',\n",
      "       'jc', 'univ', 'lwage', 'stotal', 'smcity', 'medcity', 'submed',\n",
      "       'lgcity', 'sublg', 'vlgcity', 'subvlg', 'ne', 'nc', 'south', 'totcoll'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar los datos\n",
    "data = woo.data('twoyear')\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas descriptivas para phsrank (percentil de rango en la escuela secundaria):\n",
      "                         Valor\n",
      "Mínimo                0.000000\n",
      "Máximo               99.000000\n",
      "Promedio             56.157031\n",
      "Mediana              50.000000\n",
      "Desviación estándar  24.272964\n"
     ]
    }
   ],
   "source": [
    "# Calcular estadísticas descriptivas para phsrank\n",
    "phsrank_stats = {\n",
    "    'Mínimo': data['phsrank'].min(),\n",
    "    'Máximo': data['phsrank'].max(),\n",
    "    'Promedio': data['phsrank'].mean(),\n",
    "    'Mediana': data['phsrank'].median(),\n",
    "    'Desviación estándar': data['phsrank'].std()\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame.from_dict(phsrank_stats, orient='index', columns=['Valor'])\n",
    "print(\"Estadísticas descriptivas para phsrank (percentil de rango en la escuela secundaria):\")\n",
    "print(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.4587      0.024     61.756      0.000       1.412       1.505\n",
      "jc             0.0662      0.007      9.671      0.000       0.053       0.080\n",
      "univ           0.0755      0.003     29.496      0.000       0.070       0.080\n",
      "exper          0.0049      0.000     31.360      0.000       0.005       0.005\n",
      "phsrank        0.0003      0.000      1.269      0.204      -0.000       0.001\n",
      "==============================================================================\n",
      "\n",
      "R-cuadrado: 0.2226\n",
      "Número de observaciones: 6763.0\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# log(wage) = β₀ + β₁jc + β₂univ + β₃exper + β₄phsrank + u\n",
    "model = ols('lwage ~ jc + univ + exper + phsrank', data=data)\n",
    "results = model.fit()\n",
    "print(results.summary().tables[1])\n",
    "\n",
    "# Calcular R-cuadrado\n",
    "print(\"\\nR-cuadrado:\", round(results.rsquared, 4))\n",
    "print(\"Número de observaciones:\", results.nobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phsrank:\n",
    "\n",
    "Not statistically significant (t = 1.26)\n",
    "Increasing 10 percentile points produce a change of 0.3% in salary (.0003 × 10 × 100)\n",
    "\n",
    "Adding phsrank doesn't change the conclusions of the model without it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hogares unipersonales: 2017\n",
      "\n",
      "Resultados de la Regresión:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -43.0398      4.080    -10.548      0.000     -51.042     -35.038\n",
      "inc            0.7993      0.060     13.382      0.000       0.682       0.916\n",
      "age            0.8427      0.092      9.158      0.000       0.662       1.023\n",
      "==============================================================================\n",
      "\n",
      "R-cuadrado: 0.1193\n",
      "R-cuadrado ajustado: 0.1185\n",
      "\n",
      "Diagnósticos del modelo:\n",
      "Test F (p-valor): 0.0000\n",
      "Estadístico F: 136.4648\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wooldridge as wd\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Cargar los datos\n",
    "data = wd.data('401ksubs')\n",
    "\n",
    "# Filtrar solo hogares unipersonales\n",
    "single_household = data[data['fsize'] == 1].copy()\n",
    "\n",
    "# (i) Número de hogares unipersonales\n",
    "n_singles = len(single_household)\n",
    "print(f\"Número de hogares unipersonales: {n_singles}\")\n",
    "\n",
    "# (ii) Estimación del modelo OLS\n",
    "# Crear el modelo\n",
    "model = ols('nettfa ~ inc + age', data=single_household)\n",
    "results = model.fit()\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\nResultados de la Regresión:\")\n",
    "print(results.summary().tables[1])\n",
    "\n",
    "# Calcular R-cuadrado\n",
    "r2 = results.rsquared\n",
    "r2_adj = results.rsquared_adj\n",
    "\n",
    "print(f\"\\nR-cuadrado: {r2:.4f}\")\n",
    "print(f\"R-cuadrado ajustado: {r2_adj:.4f}\")\n",
    "\n",
    "# Diagnósticos básicos\n",
    "print(\"\\nDiagnósticos del modelo:\")\n",
    "print(f\"Test F (p-valor): {results.f_pvalue:.4f}\")\n",
    "print(f\"Estadístico F: {results.fvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente de age (β₂): 0.8427\n",
      "Error estándar: 0.0920\n",
      "Estadístico t: -1.7099\n",
      "P-valor: 0.0874\n",
      "\n",
      "Comparación de coeficientes de ingreso:\n",
      "Modelo múltiple: 0.7993\n",
      "Modelo simple: 0.8207\n"
     ]
    }
   ],
   "source": [
    "# Extraer coeficiente y error estándar para age\n",
    "beta_2 = results.params['age']\n",
    "se_beta_2 = results.bse['age']\n",
    "\n",
    "# Calcular el estadístico t para H0: β₂ = 1\n",
    "t_stat = (beta_2 - 1) / se_beta_2\n",
    "\n",
    "# Calcular el p-valor (prueba de dos colas)\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=len(single_household)-3))\n",
    "\n",
    "print(f\"Coeficiente de age (β₂): {beta_2:.4f}\")\n",
    "print(f\"Error estándar: {se_beta_2:.4f}\")\n",
    "print(f\"Estadístico t: {t_stat:.4f}\")\n",
    "print(f\"P-valor: {p_value:.4f}\")\n",
    "\n",
    "# Comparación con regresión simple\n",
    "simple_model = ols('nettfa ~ inc', data=single_household)\n",
    "simple_results = simple_model.fit()\n",
    "\n",
    "print(\"\\nComparación de coeficientes de ingreso:\")\n",
    "print(f\"Modelo múltiple: {results.params['inc']:.4f}\")\n",
    "print(f\"Modelo simple: {simple_results.params['inc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept has no practical meaning in this problem. \n",
    "\n",
    "There is no evidence to reject that the effect on age is different than 1.\n",
    "\n",
    "The coefficient has little change over a simple regression model, which suggests low correlation between these two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C9\n",
    "\n",
    "This problem investigates if racial discrimination exists in soft drink prices at fast-food restaurants by analyzing whether the percentage of black population in a zip code significantly influences prices, while controlling for socioeconomic variables such as income, poverty rates, housing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['psoda', 'pfries', 'pentree', 'wagest', 'nmgrs', 'nregs', 'hrsopen',\n",
      "       'emp', 'psoda2', 'pfries2', 'pentree2', 'wagest2', 'nmgrs2', 'nregs2',\n",
      "       'hrsopen2', 'emp2', 'compown', 'chain', 'density', 'crmrte', 'state',\n",
      "       'prpblck', 'prppov', 'prpncar', 'hseval', 'nstores', 'income', 'county',\n",
      "       'lpsoda', 'lpfries', 'lhseval', 'lincome', 'ldensity', 'NJ', 'BK',\n",
      "       'KFC', 'RR'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# Cargamos los datos\n",
    "data = woo.data('discrim')\n",
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información sobre valores faltantes antes de la limpieza:\n",
      "lpsoda     8\n",
      "prpblck    1\n",
      "lincome    1\n",
      "prppov     1\n",
      "dtype: int64\n",
      "\n",
      "Información sobre valores infinitos antes de la limpieza:\n",
      "lpsoda     0\n",
      "prpblck    0\n",
      "lincome    0\n",
      "prppov     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificamos valores faltantes o infinitos\n",
    "print(\"Información sobre valores faltantes antes de la limpieza:\")\n",
    "print(data[['lpsoda', 'prpblck', 'lincome', 'prppov']].isna().sum())\n",
    "print(\"\\nInformación sobre valores infinitos antes de la limpieza:\")\n",
    "print(np.isinf(data[['lpsoda', 'prpblck', 'lincome', 'prppov']]).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño del dataset:\n",
      "Original: 410\n",
      "Después de limpiar: 401\n"
     ]
    }
   ],
   "source": [
    "variables_modelo = ['lpsoda', 'prpblck', 'lincome', 'prppov']\n",
    "data_clean = data[variables_modelo].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "print(\"\\nTamaño del dataset:\")\n",
    "print(f\"Original: {len(data)}\")\n",
    "print(f\"Después de limpiar: {len(data_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la Regresión:\n",
      "==========================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 lpsoda   R-squared:                       0.087\n",
      "Model:                            OLS   Adj. R-squared:                  0.080\n",
      "Method:                 Least Squares   F-statistic:                     12.60\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           6.92e-08\n",
      "Time:                        18:52:00   Log-Likelihood:                 439.04\n",
      "No. Observations:                 401   AIC:                            -870.1\n",
      "Df Residuals:                     397   BIC:                            -854.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.4633      0.294     -4.982      0.000      -2.041      -0.886\n",
      "prpblck        0.0728      0.031      2.373      0.018       0.013       0.133\n",
      "lincome        0.1370      0.027      5.119      0.000       0.084       0.190\n",
      "prppov         0.3804      0.133      2.864      0.004       0.119       0.641\n",
      "==============================================================================\n",
      "Omnibus:                       12.002   Durbin-Watson:                   1.727\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               24.056\n",
      "Skew:                          -0.014   Prob(JB):                     5.97e-06\n",
      "Kurtosis:                       4.200   Cond. No.                         834.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data_clean[['prpblck', 'lincome', 'prppov']]\n",
    "X = sm.add_constant(X)  # Añadimos la constante\n",
    "y = data_clean['lpsoda']\n",
    "\n",
    "# Estimamos el modelo\n",
    "modelo = sm.OLS(y, X).fit()\n",
    "\n",
    "# Imprimimos los resultados\n",
    "print(\"Resultados de la Regresión:\")\n",
    "print(\"==========================\")\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis específico del coeficiente de prpblck (β1)\n",
    "beta1 = modelo.params['prpblck']\n",
    "se_beta1 = modelo.bse['prpblck']\n",
    "t_stat = beta1 / se_beta1\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=modelo.df_resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Análisis detallado del coeficiente de prpblck (β1):\n",
      "=================================================\n",
      "Coeficiente (β1): 0.0728\n",
      "Error estándar: 0.0307\n",
      "Estadístico t: 2.3735\n",
      "Valor p: 0.0181\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAnálisis detallado del coeficiente de prpblck (β1):\")\n",
    "print(\"=================================================\")\n",
    "print(f\"Coeficiente (β1): {beta1:.4f}\")\n",
    "print(f\"Error estándar: {se_beta1:.4f}\")\n",
    "print(f\"Estadístico t: {t_stat:.4f}\")\n",
    "print(f\"Valor p: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruebas de Significancia:\n",
      "========================\n",
      "Valor crítico al 5%: 1.9660\n",
      "Valor crítico al 1%: 2.5883\n",
      "Significativo al 5%: Sí\n",
      "Significativo al 1%: No\n"
     ]
    }
   ],
   "source": [
    "# Análisis de significancia\n",
    "alpha_5 = 0.05\n",
    "alpha_1 = 0.01\n",
    "\n",
    "print(\"\\nPruebas de Significancia:\")\n",
    "print(\"========================\")\n",
    "print(f\"Valor crítico al 5%: {stats.t.ppf(1-alpha_5/2, df=modelo.df_resid):.4f}\")\n",
    "print(f\"Valor crítico al 1%: {stats.t.ppf(1-alpha_1/2, df=modelo.df_resid):.4f}\")\n",
    "print(f\"Significativo al 5%: {'Sí' if p_value < alpha_5 else 'No'}\")\n",
    "print(f\"Significativo al 1%: {'Sí' if p_value < alpha_1 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intervalos de Confianza para β1:\n",
      "===============================\n",
      "Intervalo de confianza al 95%: [0.0125, 0.1331]\n",
      "Intervalo de confianza al 99%: [-0.0066, 0.1522]\n"
     ]
    }
   ],
   "source": [
    "# Intervalos de confianza\n",
    "ci_95 = modelo.conf_int().loc['prpblck']\n",
    "ci_99 = modelo.conf_int(alpha=0.01).loc['prpblck']\n",
    "\n",
    "print(\"\\nIntervalos de Confianza para β1:\")\n",
    "print(\"===============================\")\n",
    "print(f\"Intervalo de confianza al 95%: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]\")\n",
    "print(f\"Intervalo de confianza al 99%: [{ci_99[0]:.4f}, {ci_99[1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlación entre log(income) y prppov:\n",
      "r = -0.8402\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la correlación entre lincome y prppov\n",
    "correlation = data_clean['lincome'].corr(data_clean['prppov'])\n",
    "\n",
    "print(\"Correlación entre log(income) y prppov:\")\n",
    "print(f\"r = {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados del nuevo modelo (incluyendo lhseval):\n",
      "===============================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 lpsoda   R-squared:                       0.184\n",
      "Model:                            OLS   Adj. R-squared:                  0.176\n",
      "Method:                 Least Squares   F-statistic:                     22.31\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           1.24e-16\n",
      "Time:                        18:58:13   Log-Likelihood:                 461.55\n",
      "No. Observations:                 401   AIC:                            -913.1\n",
      "Df Residuals:                     396   BIC:                            -893.1\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.8415      0.292     -2.878      0.004      -1.416      -0.267\n",
      "prpblck        0.0976      0.029      3.334      0.001       0.040       0.155\n",
      "lincome       -0.0530      0.038     -1.412      0.159      -0.127       0.021\n",
      "prppov         0.0521      0.134      0.388      0.699      -0.212       0.317\n",
      "lhseval        0.1213      0.018      6.860      0.000       0.087       0.156\n",
      "==============================================================================\n",
      "Omnibus:                       16.452   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.077\n",
      "Skew:                          -0.016   Prob(JB):                     1.98e-09\n",
      "Kurtosis:                       4.548   Cond. No.                     1.31e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.31e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_clean = data[['lpsoda', 'prpblck', 'lincome', 'prppov', 'lhseval']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Añadimos log(hseval)\n",
    "X_new = data_clean[['prpblck', 'lincome', 'prppov', 'lhseval']]\n",
    "X_new = sm.add_constant(X_new)\n",
    "y = data_clean['lpsoda']\n",
    "\n",
    "modelo_nuevo = sm.OLS(y, X_new).fit()\n",
    "\n",
    "print(\"\\nResultados del nuevo modelo (incluyendo lhseval):\")\n",
    "print(\"===============================================\")\n",
    "print(modelo_nuevo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prueba de significancia conjunta para lincome y prppov:\n",
      "Estadístico F: 3.5227\n",
      "Valor p: 0.0304\n"
     ]
    }
   ],
   "source": [
    "# Parte (iv) - Prueba F para significancia conjunta de lincome y prppov\n",
    "# Creamos el modelo restringido (sin lincome y prppov)\n",
    "X_restricted = data_clean[['prpblck', 'lhseval']]\n",
    "X_restricted = sm.add_constant(X_restricted)\n",
    "modelo_restringido = sm.OLS(y, X_restricted).fit()\n",
    "\n",
    "# Realizamos la prueba F\n",
    "f_stat = ((modelo_restringido.ssr - modelo_nuevo.ssr) / 2) / (modelo_nuevo.ssr / modelo_nuevo.df_resid)\n",
    "p_value_f = 1 - stats.f.cdf(f_stat, 2, modelo_nuevo.df_resid)\n",
    "\n",
    "print(\"\\nPrueba de significancia conjunta para lincome y prppov:\")\n",
    "print(f\"Estadístico F: {f_stat:.4f}\")\n",
    "print(f\"Valor p: {p_value_f:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis reveals that the prpblck coefficient is significant at 5% but not at 1% in the initial model.  (β₁=0.0728, p=0.0181)\n",
    "\n",
    "There is a strong negative correlation between lincome and prppov, (r=-0.8402) indicating multicollinearity. \n",
    "\n",
    "adding lhseval (avg housing prices in the zip code), the prpblck coefficient becomes more significant  (β₁=0.0976, p=0.001) while lincome and prppov lose individual significance, but mantain joint significance  (p=0.0304)\n",
    "\n",
    "The first model, which only has prpblck (p=0.018) might be capturing both racial and socioeconomic effects.\n",
    "\n",
    "The second model, with lhseval, should be capturing better the socioeconomic effect. Including this to the model allows us to separate both racial and economic discrimination. Even though there is a clear multicolinallity problem, which might require more discussion to select the proper model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C10\n",
    "\n",
    "The study examines the relationship between salaries and benefits in the school system, specifically analyzing whether there is a trade-off between these compensation components. It seeks to determine if schools offering higher benefits (measured as a benefits-to-salary ratio) tend to pay lower salaries, controlling for factors such as school size (enrollment), staff, and students' socioeconomic status (lunch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 1: Regresión Simple\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                lavgsal   R-squared:                       0.015\n",
      "Model:                            OLS   Adj. R-squared:                  0.015\n",
      "Method:                 Least Squares   F-statistic:                     28.23\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           1.21e-07\n",
      "Time:                        19:18:51   Log-Likelihood:                 85.171\n",
      "No. Observations:                1848   AIC:                            -166.3\n",
      "Df Residuals:                    1846   BIC:                            -155.3\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.7479      0.052    208.042      0.000      10.647      10.849\n",
      "bs            -0.7951      0.150     -5.313      0.000      -1.089      -0.502\n",
      "==============================================================================\n",
      "Omnibus:                       47.654   Durbin-Watson:                   0.932\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               76.684\n",
      "Skew:                          -0.231   Prob(JB):                     2.23e-17\n",
      "Kurtosis:                       3.884   Cond. No.                         31.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Test de hipótesis para β = -1:\n",
      "t-estadístico: 1.3690\n",
      "p-valor: 0.1712\n",
      "\n",
      "Modelo 2: Regresión Múltiple\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                lavgsal   R-squared:                       0.482\n",
      "Model:                            OLS   Adj. R-squared:                  0.481\n",
      "Method:                 Least Squares   F-statistic:                     572.0\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):          9.17e-263\n",
      "Time:                        19:18:51   Log-Likelihood:                 679.00\n",
      "No. Observations:                1848   AIC:                            -1350.\n",
      "Df Residuals:                    1844   BIC:                            -1328.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.9530      0.107    130.118      0.000      13.743      14.163\n",
      "bs            -0.6051      0.109     -5.564      0.000      -0.818      -0.392\n",
      "lenrol        -0.0316      0.008     -3.726      0.000      -0.048      -0.015\n",
      "lstaff        -0.7137      0.018    -40.119      0.000      -0.749      -0.679\n",
      "==============================================================================\n",
      "Omnibus:                       43.688   Durbin-Watson:                   0.894\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               94.137\n",
      "Skew:                           0.061   Prob(JB):                     3.62e-21\n",
      "Kurtosis:                       4.099   Cond. No.                         235.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Modelo 3: Regresión con lunch\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                lavgsal   R-squared:                       0.488\n",
      "Model:                            OLS   Adj. R-squared:                  0.487\n",
      "Method:                 Least Squares   F-statistic:                     439.4\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):          4.22e-266\n",
      "Time:                        19:18:51   Log-Likelihood:                 689.98\n",
      "No. Observations:                1848   AIC:                            -1370.\n",
      "Df Residuals:                    1843   BIC:                            -1342.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.8315      0.110    126.055      0.000      13.616      14.047\n",
      "bs            -0.5161      0.110     -4.702      0.000      -0.731      -0.301\n",
      "lenrol        -0.0284      0.008     -3.360      0.001      -0.045      -0.012\n",
      "lstaff        -0.6906      0.018    -37.615      0.000      -0.727      -0.655\n",
      "lunch         -0.0008      0.000     -4.695      0.000      -0.001      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                       46.324   Durbin-Watson:                   0.921\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              105.674\n",
      "Skew:                           0.009   Prob(JB):                     1.13e-23\n",
      "Kurtosis:                       4.171   Cond. No.                     1.46e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.46e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Comparación de R²:\n",
      "R² Modelo 1: 0.0151\n",
      "R² Modelo 2: 0.4820\n",
      "R² Modelo 3: 0.4882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gerardo\\AppData\\Local\\Temp\\ipykernel_4760\\3571619949.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta_hat = model1.params[1]\n",
      "C:\\Users\\Gerardo\\AppData\\Local\\Temp\\ipykernel_4760\\3571619949.py:20: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  se_beta = model1.bse[1]\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Cargar los datos\n",
    "data = woo.data('elem94_95')\n",
    "\n",
    "# (i) Regresión simple de lavgsal sobre bs\n",
    "X = data['bs']\n",
    "y = data['lavgsal']\n",
    "X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X).fit()\n",
    "print(\"Modelo 1: Regresión Simple\")\n",
    "print(model1.summary())\n",
    "\n",
    "# Test de hipótesis para β = -1\n",
    "beta_hat = model1.params[1]\n",
    "se_beta = model1.bse[1]\n",
    "t_stat = (beta_hat - (-1)) / se_beta\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), model1.df_resid))\n",
    "\n",
    "print(\"\\nTest de hipótesis para β = -1:\")\n",
    "print(f\"t-estadístico: {t_stat:.4f}\")\n",
    "print(f\"p-valor: {p_value:.4f}\")\n",
    "\n",
    "# (ii) Regresión múltiple añadiendo lenrol y lstaff\n",
    "X2 = data[['bs', 'lenrol', 'lstaff']]\n",
    "X2 = sm.add_constant(X2)\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "print(\"\\nModelo 2: Regresión Múltiple\")\n",
    "print(model2.summary())\n",
    "\n",
    "# (v) Añadir la variable lunch\n",
    "X3 = data[['bs', 'lenrol', 'lstaff', 'lunch']]\n",
    "X3 = sm.add_constant(X3)\n",
    "model3 = sm.OLS(y, X3).fit()\n",
    "print(\"\\nModelo 3: Regresión con lunch\")\n",
    "print(model3.summary())\n",
    "\n",
    "# Calcular R² para cada modelo\n",
    "r2_1 = model1.rsquared\n",
    "r2_2 = model2.rsquared\n",
    "r2_3 = model3.rsquared\n",
    "\n",
    "print(\"\\nComparación de R²:\")\n",
    "print(f\"R² Modelo 1: {r2_1:.4f}\")\n",
    "print(f\"R² Modelo 2: {r2_2:.4f}\")\n",
    "print(f\"R² Modelo 3: {r2_3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analyses confirm a negative trade-off between salaries and benefits: for each unit increase in the benefits-to-salary ratio, salaries decrease by approximately 51.6% (in the full model). This relationship remains significant even after controlling for school size, staff, and student socioeconomic characteristics, although its magnitude reduces when including these controls (from -79.5% in the simple model to -51.6% in the full model). The final model explains 48.8% of the variation in salaries (R² = 0.4882).\n",
    "\n",
    "(i) We can't reject that β = -1\n",
    "\n",
    "(ii) b/s becomes less negative when we add other variables. It stays significant (p-value < .001) and R² increases substantially\n",
    "\n",
    "(iii) when adding the variables, the standard error reduces. When compared to multicolineality, the reduction in variance is stronger. This can be explained by the drastic increase in R²\n",
    "\n",
    "(iv) lstaff seems to be negative and large in magnitude. This reflects a tradeoff between the number of workers and the salary\n",
    "\n",
    "(v) adding lunch decreases salaries because lunch program is a proxy to lower socioeconomic power. Therefore, if a school is on a zone with higher poverty levels, then the salaries are expected to drop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C11\n",
    "\n",
    "This study analyzes the determinants of the years of education in a person, using parental education, student's ability (including a cuadratic term to capture non-linear effects) and college tuition costs as explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo inicial:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   educ   R-squared:                       0.444\n",
      "Model:                            OLS   Adj. R-squared:                  0.443\n",
      "Method:                 Least Squares   F-statistic:                     244.9\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):          1.34e-154\n",
      "Time:                        19:42:26   Log-Likelihood:                -2436.6\n",
      "No. Observations:                1230   AIC:                             4883.\n",
      "Df Residuals:                    1225   BIC:                             4909.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          8.2402      0.287     28.671      0.000       7.676       8.804\n",
      "motheduc       0.1901      0.028      6.767      0.000       0.135       0.245\n",
      "fatheduc       0.1089      0.020      5.558      0.000       0.070       0.147\n",
      "abil           0.4015      0.030     13.255      0.000       0.342       0.461\n",
      "abil2          0.0506      0.008      6.093      0.000       0.034       0.067\n",
      "==============================================================================\n",
      "Omnibus:                       45.933   Durbin-Watson:                   1.820\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               56.769\n",
      "Skew:                           0.404   Prob(JB):                     4.71e-13\n",
      "Kurtosis:                       3.674   Cond. No.                         115.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Test para relación cuadrática:\n",
      "t-estadístico para abil2: 6.0934\n",
      "p-valor para abil2: 0.0000\n",
      "\n",
      "Test de igualdad entre coeficientes de motheduc y fatheduc:\n",
      "t-estadístico: 1.9357\n",
      "p-valor: 0.0531\n",
      "\n",
      "Test conjunto para variables de matrícula:\n",
      "F-estadístico: 0.8393\n",
      "p-valor: 0.4322\n",
      "\n",
      "Correlación entre tuit17 y tuit18: 0.9808\n",
      "\n",
      "Modelo con promedio de matrícula:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   educ   R-squared:                       0.445\n",
      "Model:                            OLS   Adj. R-squared:                  0.443\n",
      "Method:                 Least Squares   F-statistic:                     196.4\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):          9.75e-154\n",
      "Time:                        19:42:27   Log-Likelihood:                -2435.8\n",
      "No. Observations:                1230   AIC:                             4884.\n",
      "Df Residuals:                    1224   BIC:                             4914.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          8.0813      0.313     25.851      0.000       7.468       8.695\n",
      "motheduc       0.1929      0.028      6.847      0.000       0.138       0.248\n",
      "fatheduc       0.1084      0.020      5.529      0.000       0.070       0.147\n",
      "abil           0.3991      0.030     13.156      0.000       0.340       0.459\n",
      "abil2          0.0506      0.008      6.095      0.000       0.034       0.067\n",
      "tuit_avg       0.0160      0.012      1.290      0.197      -0.008       0.040\n",
      "==============================================================================\n",
      "Omnibus:                       45.884   Durbin-Watson:                   1.824\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               56.400\n",
      "Skew:                           0.406   Prob(JB):                     5.66e-13\n",
      "Kurtosis:                       3.664   Cond. No.                         136.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gerardo\\AppData\\Local\\Temp\\ipykernel_4760\\2605916308.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(f\"t-estadístico: {float(test_result.statistic):.4f}\")\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargamos los datos\n",
    "data = woo.data('htv')\n",
    "\n",
    "# (i) Estimamos el modelo de regresión\n",
    "# Creamos la variable abil al cuadrado\n",
    "data['abil2'] = data['abil']**2\n",
    "\n",
    "# Creamos el modelo con statsmodels\n",
    "X = sm.add_constant(data[['motheduc', 'fatheduc', 'abil', 'abil2']])\n",
    "y = data['educ']\n",
    "\n",
    "# Estimamos el modelo\n",
    "modelo1 = sm.OLS(y, X).fit()\n",
    "print(\"Resultados del modelo inicial:\")\n",
    "print(modelo1.summary())\n",
    "\n",
    "# Test para relación lineal vs cuadrática (H0: coef_abil2 = 0)\n",
    "print(\"\\nTest para relación cuadrática:\")\n",
    "print(f\"t-estadístico para abil2: {modelo1.tvalues['abil2']:.4f}\")\n",
    "print(f\"p-valor para abil2: {modelo1.pvalues['abil2']:.4f}\")\n",
    "\n",
    "# (ii) Test H0: β1 = β2\n",
    "# Creamos una matriz R para el test de restricción lineal\n",
    "R = np.array([[0, 1, -1, 0, 0]])  # motheduc - fatheduc = 0\n",
    "test_result = modelo1.t_test(R)\n",
    "print(\"\\nTest de igualdad entre coeficientes de motheduc y fatheduc:\")\n",
    "print(f\"t-estadístico: {float(test_result.statistic):.4f}\")\n",
    "print(f\"p-valor: {float(test_result.pvalue):.4f}\")\n",
    "\n",
    "# (iii) Agregamos variables de matrícula\n",
    "X2 = sm.add_constant(data[['motheduc', 'fatheduc', 'abil', 'abil2', 'tuit17', 'tuit18']])\n",
    "modelo2 = sm.OLS(y, X2).fit()\n",
    "\n",
    "# Test conjunto para las variables de matrícula\n",
    "R2 = np.zeros((2, 7))  # 7 es el número de parámetros en el modelo2\n",
    "R2[0, 5] = 1  # coeficiente de tuit17\n",
    "R2[1, 6] = 1  # coeficiente de tuit18\n",
    "test_result2 = modelo2.f_test(R2)\n",
    "print(\"\\nTest conjunto para variables de matrícula:\")\n",
    "print(f\"F-estadístico: {float(test_result2.statistic):.4f}\")\n",
    "print(f\"p-valor: {float(test_result2.pvalue):.4f}\")\n",
    "\n",
    "# (iv) Correlación entre tuit17 y tuit18\n",
    "corr = data['tuit17'].corr(data['tuit18'])\n",
    "print(f\"\\nCorrelación entre tuit17 y tuit18: {corr:.4f}\")\n",
    "\n",
    "# Creamos el promedio de matrícula\n",
    "data['tuit_avg'] = (data['tuit17'] + data['tuit18']) / 2\n",
    "\n",
    "# Modelo con promedio de matrícula\n",
    "X3 = sm.add_constant(data[['motheduc', 'fatheduc', 'abil', 'abil2', 'tuit_avg']])\n",
    "modelo3 = sm.OLS(y, X3).fit()\n",
    "print(\"\\nModelo con promedio de matrícula:\")\n",
    "print(modelo3.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model explains 44.4% of the variation in years of education, where both parental education and student's ability are statistically significant. There is a stronger effect in mother's education(0.19 years) compared to father's education (0.11 years). The relationship between ability and education is quadratic, confirmed by a significant abil^2 term.  Tuition costs, however, show no significant effect on years of education, even when using the average of both periods due to their high correlation.\n",
    "\n",
    "(i) H₀: β₄abil² = 0 H₁: β₄ ≠ 0. With a t-statistic of 6.093, we know the relation is quadratic.\n",
    "(ii) H0: β1 = β2. With a t-statistic of 1.93, we cant reject that these coefficients (mother and father educ) are equal. However, we have evidence to reject it at 10%\n",
    "(iii) We cant reject that tuition isn't 0.\n",
    "(iv) tuit17 and tuit18 are highly correlated. It is better to use the average of both due to their correlation. Averaging both years (which are highly correlated at 0.9808) is preferred as it reduces measurement error, provides a more representative measure of the true tuition costs faced by students, and still maintains model parsimony while avoiding multicollinearity issues.\n",
    "(v) Including the average tuition didn't change R², and isn't statistically significant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScikitLearn Tutorial Venv",
   "language": "python",
   "name": "scikitlearn_tutorial_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
